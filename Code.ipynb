{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Loading the data "
      ],
      "metadata": {
        "id": "MAnt8FmBAlRL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jn7PT76jxcjb"
      },
      "outputs": [],
      "source": [
        "doc1 = \"For future work, we plan to consolidate the results of this systematic mapping and providing an in-depth classification of the available game approaches and support for software engineering education knowledge areas.\"\n",
        "doc2 = \"In the future, we will first improve our model for achieving better quality by taking the app metadata into the consideration. Second, we will also try to test the quality of existing labels by checking if the description is concise and informative.\"\n",
        "doc3 = \"In future, an empirical study will be conductedto validate these challenges identified through literature aswell as to investigate new challenges at different levels.\"\n",
        "\n",
        "\n",
        "doc_complete = [doc1, doc2, doc3]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Jt0ANLC-LUi",
        "outputId": "2f0dcd0c-5df1-4321-cd9b-01339cb59206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleaning"
      ],
      "metadata": {
        "id": "wcryL-5uyYSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import string\n",
        "stop = set(stopwords.words('english'))\n",
        "exclude = set(string.punctuation)\n",
        "lemma = WordNetLemmatizer()\n",
        "\n",
        "def clean(doc):\n",
        "    stop_free = ' '.join([i for i in doc.lower().split() if i not in stop])\n",
        "    punc_free = ''.join([ch for ch in stop_free if ch not in exclude])\n",
        "    normalized = ' '.join(lemma.lemmatize(word) for word in punc_free.split())\n",
        "    return normalized\n",
        "doc_clean = [clean(doc).split() for doc in doc_complete]"
      ],
      "metadata": {
        "id": "csGWged7yNlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim import corpora\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "dictionary = corpora.Dictionary(doc_clean)\n",
        "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n"
      ],
      "metadata": {
        "id": "m8iIhKhHyNzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the model\n"
      ],
      "metadata": {
        "id": "UlfrknUIyShJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Lda = gensim.models.ldamodel.LdaModel\n",
        "ldamodel = Lda(doc_term_matrix, num_topics = 3, id2word = dictionary, passes=50)"
      ],
      "metadata": {
        "id": "7KGDm21xyuPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ldamodel.print_topics(num_topics=3, num_words=3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VELFRDjpyuSn",
        "outputId": "de6017a6-5436-42ec-c22b-483336d56760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, '0.037*\"future\" + 0.037*\"engineering\" + 0.037*\"software\"'), (1, '0.075*\"challenge\" + 0.043*\"future\" + 0.043*\"different\"'), (2, '0.060*\"quality\" + 0.034*\"future\" + 0.034*\"second\"')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=ldamodel, texts=doc_clean, dictionary=dictionary, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "metadata": {
        "id": "oc08x521yuWI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9caf2d7f-c6a6-4f3c-9824-9eafad235e27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Coherence Score:  0.6852783249244073\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docc=\"In future A deep investigation and experimentation of new approaches to aggregate holistic data is needed to understand which solutions achieve better performance.\""
      ],
      "metadata": {
        "id": "xwvI-Hck5mjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean(docc):\n",
        "    stop_free = ' '.join([i for i in docc.lower().split() if i not in stop])\n",
        "    punc_free = ''.join([ch for ch in stop_free if ch not in exclude])\n",
        "    normalized = ' '.join(lemma.lemmatize(word) for word in punc_free.split())\n",
        "    return normalized\n",
        "docc_clean = [clean(docc).split()]"
      ],
      "metadata": {
        "id": "rcKGSruE5kqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docc_term_matrix = [dictionary.doc2bow(doc) for doc in docc_clean]"
      ],
      "metadata": {
        "id": "jLc6I8lX5ktA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docc_term_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41G9PEiG8rz4",
        "outputId": "f3f7da6e-8e53-4e07-ec39-5b8ef7d1a4e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(0, 1), (7, 1), (22, 1), (48, 1)]]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the model\n"
      ],
      "metadata": {
        "id": "sCsrbCtyAUv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Lda = gensim.models.ldamodel.LdaModel\n",
        "ldamodel = Lda(docc_term_matrix, num_topics = 3, id2word = dictionary, passes=50)"
      ],
      "metadata": {
        "id": "VMYg58Fp5kwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ldamodel.print_topics(num_topics=1, num_words=3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqArSct16bfo",
        "outputId": "e975a944-a620-4132-fe47-84140ce72e95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, '0.063*\"better\" + 0.063*\"new\" + 0.063*\"future\"')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2fMqDvRo6bld"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}